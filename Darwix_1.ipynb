{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f25b4aa-5345-442f-a7ee-6e03f053b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' model.\n",
      "It might be because the model is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Model.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                       use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the model is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the diarization model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m diarization_model \u001b[38;5;241m=\u001b[39m Inference(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/speaker-diarization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the multilingual transcription model (using Hugging Face transformers)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m transcription_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautomatic-speech-recognition\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/wav2vec2-large-xlsr-53\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyannote/audio/core/inference.py:110\u001b[0m, in \u001b[0;36mInference.__init__\u001b[0;34m(self, model, window, duration, step, pre_aggregation_hook, skip_aggregation, skip_conversion, device, batch_size, use_auth_token)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     99\u001b[0m     model\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Model)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import speech_recognition as sr\n",
    "from pyannote.audio import Inference\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the diarization model\n",
    "diarization_model = Inference(\"pyannote/speaker-diarization\")\n",
    "\n",
    "# Load the multilingual transcription model (using Hugging Face transformers)\n",
    "transcription_pipeline = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-large-xlsr-53\")\n",
    "\n",
    "def transcribe_audio_with_diarization(audio_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    # Convert audio to wav format (if not already in wav format)\n",
    "    wav_audio_path = \"temp_audio.wav\"\n",
    "    audio.export(wav_audio_path, format=\"wav\")\n",
    "    \n",
    "    # Step 1: Perform speaker diarization (speaker separation)\n",
    "    diarization = diarization_model(wav_audio_path)\n",
    "    \n",
    "    # Step 2: Transcribe the audio using the ASR model\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    \n",
    "    # Use the transcription model to get the transcriptions\n",
    "    transcription_result = transcription_pipeline(wav_audio_path)\n",
    "    \n",
    "    # Step 3: Structure the output in JSON format with diarization info\n",
    "    speakers = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speakers.append({\"start_time\": turn.start, \"end_time\": turn.end, \"speaker\": speaker})\n",
    "\n",
    "    # Combine the transcription with speaker diarization data\n",
    "    output = {\n",
    "        \"transcription\": transcription_result[\"text\"],\n",
    "        \"speaker_diarization\": speakers\n",
    "    }\n",
    "\n",
    "    return json.dumps(output, indent=4)\n",
    "\n",
    "# Example Usage:\n",
    "audio_path = \"speech.wav\"  # Path to the audio file\n",
    "output = transcribe_audio_with_diarization(audio_path)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cb07f97-8678-4c62-a1fa-63403002221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pyannote.audio in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from SpeechRecognition) (4.13.2)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.30.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (13.3.5)\n",
      "Requirement already satisfied: semver>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.7.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2024.3.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.9.2)\n",
      "Requirement already satisfied: sympy>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: optuna>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.3.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.4)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.9.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/anaconda3/lib/python3.12/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/anaconda3/lib/python3.12/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
      "Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition pyannote.audio transformers pydub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97f5612e-8dfd-42d0-92de-62175a38e649",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2537142567.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install numpy scipy torch torchvision torchaudio librosa\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install numpy scipy torch torchvision torchaudio librosa\n",
    "pip install pyannote.audio openai-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81207c25-c264-4276-b742-9ecc317172e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3690927489.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    sudo apt install ffmpeg\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# On Linux:\n",
    "sudo apt install ffmpeg\n",
    "\n",
    "# On Mac:\n",
    "brew install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df03baa2-b0c7-4d74-b4e4-3128b05e19ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.13.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-macosx_11_0_arm64.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soxr, audioread, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soxr-0.5.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy scipy torch torchvision torchaudio librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406bf874-0dc9-4a05-8771-7932b99522c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyannote.audio in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: openai-whisper in /opt/anaconda3/lib/python3.12/site-packages (20240930)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.30.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (13.3.5)\n",
      "Requirement already satisfied: semver>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.7.1)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.59.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (10.1.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.13.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.2)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.9.2)\n",
      "Requirement already satisfied: sympy>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: optuna>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.3.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.4)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->pyannote.audio) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2023.10.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.9.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/anaconda3/lib/python3.12/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/anaconda3/lib/python3.12/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyannote.audio openai-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66206fdf-f89b-4222-b49a-23c5c2871e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n",
      "Diarization pipeline loaded successfully!\n",
      "Error during diarization: 'NoneType' object is not callable\n",
      "{\n",
      "  \"error\": \"Diarization failed\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")  # You can use \"small\", \"medium\", etc., based on your needs\n",
    "\n",
    "# Load Pyannote model for speaker diarization\n",
    "try:\n",
    "    diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "    print(\"Diarization pipeline loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading diarization pipeline: {e}\")\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio with speaker diarization.\n",
    "    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\n",
    "    :return: JSON structure with speaker info and transcriptions\n",
    "    \"\"\"\n",
    "    # Process the audio file through the diarization pipeline\n",
    "    try:\n",
    "        diarization = diarization_pipeline({'uri': 'audio', 'audio': audio_path})\n",
    "    except Exception as e:\n",
    "        print(f\"Error during diarization: {e}\")\n",
    "        return {\"error\": \"Diarization failed\"}\n",
    "    \n",
    "    segments = []\n",
    "\n",
    "    # Iterate over the diarization output to extract speaker segments\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "            start, end = turn.start, turn.end\n",
    "            temp_audio_path = temp_audio.name\n",
    "\n",
    "            # Extract segment using ffmpeg\n",
    "            os.system(f\"ffmpeg -i \\\"{audio_path}\\\" -ss {start} -to {end} -ar 16000 -ac 1 -y \\\"{temp_audio_path}\\\" -loglevel quiet\")\n",
    "\n",
    "            # Transcribe the audio segment with Whisper\n",
    "            result = whisper_model.transcribe(temp_audio_path)\n",
    "            os.remove(temp_audio_path)\n",
    "\n",
    "            # Add the transcription to the results\n",
    "            segments.append({\n",
    "                \"speaker\": speaker,\n",
    "                \"start_time\": str(start),\n",
    "                \"end_time\": str(end),\n",
    "                \"text\": result[\"text\"].strip()\n",
    "            })\n",
    "\n",
    "    return {\"transcription\": segments}\n",
    "\n",
    "\n",
    "# Usage example: transcribe the 'speech.mp3' file\n",
    "audio_file_path = \"speech-94649.mp3\"  # Path to your audio file\n",
    "\n",
    "# Get transcription results\n",
    "result = transcribe_with_diarization(audio_file_path)\n",
    "\n",
    "# Display the result as a structured JSON\n",
    "print(json.dumps(result, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d996e566-d2d9-459d-a904-476bfd81f0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/pyannote/speaker-diarization/resolve/main/config.yaml (Request ID: Root=1-67fe605a-1c3b79c00b72fc2601e131e9;eabc3eea-2b3d-4f67-9bde-39989f19770a)\n\nInvalid credentials in Authorization header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/pyannote/speaker-diarization/resolve/main/config.yaml",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m whisper_model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# You can choose other models like \"small\", \"medium\" based on your needs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load Pyannote model for speaker diarization\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m diarization_pipeline \u001b[38;5;241m=\u001b[39m Pipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/speaker-diarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_HF_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_with_diarization\u001b[39m(audio_path):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Transcribes audio with speaker diarization.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    :return: JSON structure with speaker info and transcriptions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyannote/audio/core/pipeline.py:90\u001b[0m, in \u001b[0;36mPipeline.from_pretrained\u001b[0;34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 revision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m                 config_yml \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m     91\u001b[0m                     model_id,\n\u001b[1;32m     92\u001b[0m                     PIPELINE_PARAMS_NAME,\n\u001b[1;32m     93\u001b[0m                     repo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m                     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m     95\u001b[0m                     library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m                     library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m     97\u001b[0m                     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m     98\u001b[0m                     \u001b[38;5;66;03m# force_download=False,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m                     \u001b[38;5;66;03m# proxies=None,\u001b[39;00m\n\u001b[1;32m    100\u001b[0m                     \u001b[38;5;66;03m# etag_timeout=10,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m                     \u001b[38;5;66;03m# resume_download=False,\u001b[39;00m\n\u001b[1;32m    102\u001b[0m                     use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token,\n\u001b[1;32m    103\u001b[0m                     \u001b[38;5;66;03m# local_files_only=False,\u001b[39;00m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;66;03m# legacy_cache_layout=False,\u001b[39;00m\n\u001b[1;32m    105\u001b[0m                 )\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    109\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124mCould not download \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m pipeline.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124mvisit https://hf.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to accept the user conditions.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    120\u001b[0m                 )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    943\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    963\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m    965\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    966\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    967\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    968\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    969\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m    970\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m    971\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m    972\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m    973\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    974\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m    976\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    977\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    978\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1068\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1065\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m etag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124metag must have been retrieved from server\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1596\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m hf.co look-ups and downloads online, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1590\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m   1593\u001b[0m ):\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1601\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1603\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhead_call_error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1483\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1485\u001b[0m             url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[1;32m   1486\u001b[0m         )\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1489\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1398\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1402\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1403\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1404\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1405\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1406\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1407\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1408\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1409\u001b[0m )\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    287\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    288\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    290\u001b[0m     )\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/pyannote/speaker-diarization/resolve/main/config.yaml (Request ID: Root=1-67fe605a-1c3b79c00b72fc2601e131e9;eabc3eea-2b3d-4f67-9bde-39989f19770a)\n\nInvalid credentials in Authorization header"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")  # You can choose other models like \"small\", \"medium\" based on your needs\n",
    "\n",
    "# Load Pyannote model for speaker diarization\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=\"YOUR_HF_TOKEN\")\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio with speaker diarization.\n",
    "    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\n",
    "    :return: JSON structure with speaker info and transcriptions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the audio file through the diarization pipeline\n",
    "        diarization = diarization_pipeline({'uri': 'audio', 'audio': audio_path})\n",
    "        segments = []\n",
    "\n",
    "        # Iterate over the diarization output to extract speaker segments\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "                start, end = turn.start, turn.end\n",
    "                temp_audio_path = temp_audio.name\n",
    "\n",
    "                # Extract segment using ffmpeg\n",
    "                os.system(f\"ffmpeg -i \\\"{audio_path}\\\" -ss {start} -to {end} -ar 16000 -ac 1 -y \\\"{temp_audio_path}\\\" -loglevel quiet\")\n",
    "\n",
    "                # Transcribe the audio segment with Whisper\n",
    "                result = whisper_model.transcribe(temp_audio_path)\n",
    "                os.remove(temp_audio_path)\n",
    "\n",
    "                # Add the transcription to the results\n",
    "                segments.append({\n",
    "                    \"speaker\": speaker,\n",
    "                    \"start_time\": str(start),\n",
    "                    \"end_time\": str(end),\n",
    "                    \"text\": result[\"text\"].strip()\n",
    "                })\n",
    "\n",
    "        return {\"transcription\": segments}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Usage example: transcribe the 'speech.mp3' file\n",
    "audio_file_path = \"speech-94649.mp3\"  # Path to your audio file\n",
    "\n",
    "# Get transcription results\n",
    "result = transcribe_with_diarization(audio_file_path)\n",
    "\n",
    "# Display the result as a structured JSON\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda0fc02-e5ea-4a66-bcc2-0254f60530d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n",
      "{\n",
      "  \"error\": \"Diarization failed: 'NoneType' object is not callable\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")  # You can choose other models like \"small\", \"medium\" based on your needs\n",
    "\n",
    "# Load Pyannote model for speaker diarization using your Hugging Face token\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=\"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\")\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio with speaker diarization.\n",
    "    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\n",
    "    :return: JSON structure with speaker info and transcriptions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the audio file through the diarization pipeline\n",
    "        diarization = diarization_pipeline({'uri': 'audio', 'audio': audio_path})\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Diarization failed: {str(e)}\"}\n",
    "    \n",
    "    segments = []\n",
    "\n",
    "    # Iterate over the diarization output to extract speaker segments\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "            start, end = turn.start, turn.end\n",
    "            temp_audio_path = temp_audio.name\n",
    "\n",
    "            # Extract segment using ffmpeg\n",
    "            os.system(f\"ffmpeg -i \\\"{audio_path}\\\" -ss {start} -to {end} -ar 16000 -ac 1 -y \\\"{temp_audio_path}\\\" -loglevel quiet\")\n",
    "\n",
    "            # Transcribe the audio segment with Whisper\n",
    "            result = whisper_model.transcribe(temp_audio_path)\n",
    "            os.remove(temp_audio_path)\n",
    "\n",
    "            # Add the transcription to the results\n",
    "            segments.append({\n",
    "                \"speaker\": speaker,\n",
    "                \"start_time\": str(start),\n",
    "                \"end_time\": str(end),\n",
    "                \"text\": result[\"text\"].strip()\n",
    "            })\n",
    "\n",
    "    return {\"transcription\": segments}\n",
    "\n",
    "\n",
    "# Usage example: transcribe the 'speech.mp3' file\n",
    "audio_file_path = \"speech-94649.mp3\"  # Path to your audio file\n",
    "\n",
    "# Get transcription results\n",
    "result = transcribe_with_diarization(audio_file_path)\n",
    "\n",
    "# Display the result as a structured JSON\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68816b24-29ff-472f-a934-18b188c7b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "# Use your Hugging Face authentication token\n",
    "auth_token = \"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\"\n",
    "\n",
    "# Load Pyannote model with token\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=auth_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e8a2a9-264a-4d60-b41d-cfdec53d3c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n",
      "{\n",
      "  \"error\": \"'NoneType' object is not callable\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")  # You can choose other models like \"small\", \"medium\" based on your needs\n",
    "\n",
    "# Load Pyannote model for speaker diarization with your Hugging Face authentication token\n",
    "auth_token = \"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\"  # Your Hugging Face token\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=auth_token)\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio with speaker diarization.\n",
    "    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\n",
    "    :return: JSON structure with speaker info and transcriptions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the audio file through the diarization pipeline\n",
    "        diarization = diarization_pipeline({'uri': 'audio', 'audio': audio_path})\n",
    "        segments = []\n",
    "\n",
    "        # Iterate over the diarization output to extract speaker segments\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "                start, end = turn.start, turn.end\n",
    "                temp_audio_path = temp_audio.name\n",
    "\n",
    "                # Extract segment using ffmpeg\n",
    "                os.system(f\"ffmpeg -i \\\"{audio_path}\\\" -ss {start} -to {end} -ar 16000 -ac 1 -y \\\"{temp_audio_path}\\\" -loglevel quiet\")\n",
    "\n",
    "                # Transcribe the audio segment with Whisper\n",
    "                result = whisper_model.transcribe(temp_audio_path)\n",
    "                os.remove(temp_audio_path)\n",
    "\n",
    "                # Add the transcription to the results\n",
    "                segments.append({\n",
    "                    \"speaker\": speaker,\n",
    "                    \"start_time\": str(start),\n",
    "                    \"end_time\": str(end),\n",
    "                    \"text\": result[\"text\"].strip()\n",
    "                })\n",
    "\n",
    "        return {\"transcription\": segments}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Usage example: transcribe the 'speech.mp3' file\n",
    "audio_file_path = \"speech-94649.mp3\"  # Path to your audio file\n",
    "\n",
    "# Get transcription results\n",
    "result = transcribe_with_diarization(audio_file_path)\n",
    "\n",
    "# Display the result as a structured JSON\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac68d3e-5b90-4fd2-9f59-82a3a4d8c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n",
      "Diarization pipeline loaded successfully!\n",
      "{\n",
      "  \"error\": \"'NoneType' object is not callable\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "\n",
    "# Load Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")  # You can choose other models like \"small\", \"medium\" based on your needs\n",
    "\n",
    "# Set your Hugging Face token here\n",
    "auth_token = \"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\"  # Your Hugging Face token\n",
    "\n",
    "# Load Pyannote model for speaker diarization with authentication\n",
    "try:\n",
    "    diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=auth_token)\n",
    "    print(\"Diarization pipeline loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading diarization pipeline: {e}\")\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio with speaker diarization.\n",
    "    :param audio_path: Path to the audio file (e.g., 'speech.mp3')\n",
    "    :return: JSON structure with speaker info and transcriptions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the audio file through the diarization pipeline\n",
    "        diarization = diarization_pipeline({'uri': 'audio', 'audio': audio_path})\n",
    "        segments = []\n",
    "\n",
    "        # Iterate over the diarization output to extract speaker segments\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
    "                start, end = turn.start, turn.end\n",
    "                temp_audio_path = temp_audio.name\n",
    "\n",
    "                # Extract segment using ffmpeg\n",
    "                os.system(f\"ffmpeg -i \\\"{audio_path}\\\" -ss {start} -to {end} -ar 16000 -ac 1 -y \\\"{temp_audio_path}\\\" -loglevel quiet\")\n",
    "\n",
    "                # Transcribe the audio segment with Whisper\n",
    "                result = whisper_model.transcribe(temp_audio_path)\n",
    "                os.remove(temp_audio_path)\n",
    "\n",
    "                # Add the transcription to the results\n",
    "                segments.append({\n",
    "                    \"speaker\": speaker,\n",
    "                    \"start_time\": str(start),\n",
    "                    \"end_time\": str(end),\n",
    "                    \"text\": result[\"text\"].strip()\n",
    "                })\n",
    "\n",
    "        return {\"transcription\": segments}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Usage example: transcribe the 'speech.mp3' file\n",
    "audio_file_path = \"speech-94649.mp3\"  # Path to your audio file\n",
    "\n",
    "# Get transcription results\n",
    "result = transcribe_with_diarization(audio_file_path)\n",
    "\n",
    "# Display the result as a structured JSON\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d049f88f-f9b0-4135-a300-5af39317c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: django in /opt/anaconda3/lib/python3.12/site-packages (5.2)\n",
      "Requirement already satisfied: asgiref>=3.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from django) (3.8.1)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from django) (0.5.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install django\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4be12e3-0d0a-4b59-8730-ebef84095cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog_title_suggestor/utils.py\n",
    "from transformers import pipeline\n",
    "\n",
    "def generate_titles(blog_content):\n",
    "    # Load a pre-trained model and tokenizer from Hugging Face\n",
    "    title_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "    # Generate three titles based on the blog content\n",
    "    generated_titles = title_generator(blog_content, max_length=50, num_return_sequences=3)\n",
    "    \n",
    "    # Extract and clean up the generated titles\n",
    "    titles = [title['generated_text'].strip() for title in generated_titles]\n",
    "    return titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8678bebf-ff0a-4a2c-9ed6-215f41b5a0a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# blog_title_suggestor/views.py\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdjango\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonResponse\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_titles\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_title_suggestions\u001b[39m(request):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Get the blog content from POST request\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     blog_content \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mPOST\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# blog_title_suggestor/views.py\n",
    "from django.http import JsonResponse\n",
    "from .utils import generate_titles\n",
    "\n",
    "def get_title_suggestions(request):\n",
    "    # Get the blog content from POST request\n",
    "    blog_content = request.POST.get('content')\n",
    "    \n",
    "    if not blog_content:\n",
    "        return JsonResponse({'error': 'No blog content provided'}, status=400)\n",
    "    \n",
    "    # Generate titles using the NLP model\n",
    "    titles = generate_titles(blog_content)\n",
    "    \n",
    "    # Return the titles as a JSON response\n",
    "    return JsonResponse({'titles': titles})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2adea1-71ae-47ba-a5e2-bf9507bcb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    # Load models\n",
    "    asr_model = whisper.load_model(\"medium\")\n",
    "    diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "    \n",
    "    # Perform diarization\n",
    "    diarization = diarization_pipeline(audio_path)\n",
    "    \n",
    "    # Perform transcription\n",
    "    transcription = asr_model.transcribe(audio_path, word_timestamps=True)\n",
    "    \n",
    "    # Align diarization with transcription\n",
    "    results = []\n",
    "    for segment in transcription[\"segments\"]:\n",
    "        speaker = \"Unknown\"\n",
    "        for turn, _, speaker_id in diarization.itertracks(yield_label=True):\n",
    "            if segment[\"start\"] >= turn.start and segment[\"end\"] <= turn.end:\n",
    "                speaker = speaker_id\n",
    "                break\n",
    "        \n",
    "        results.append({\n",
    "            \"start\": segment[\"start\"],\n",
    "            \"end\": segment[\"end\"],\n",
    "            \"speaker\": speaker,\n",
    "            \"text\": segment[\"text\"],\n",
    "            \"words\": segment.get(\"words\", [])\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"audio_file\": audio_path,\n",
    "        \"segments\": results,\n",
    "        \"speaker_count\": len(set([turn[2] for turn in diarization.itertracks(yield_label=True)]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea5268b-fc97-4a4a-9bb7-97968277f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting speech-94649.mp3 to WAV format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pydub/utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffprobe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m speakers in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds of audio.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[19], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Convert MP3 to WAV\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_mp3\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to WAV format...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m wav_path \u001b[38;5;241m=\u001b[39m convert_mp3_to_wav(input_mp3, output_wav)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Process the audio\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing audio with transcription and diarization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mconvert_mp3_to_wav\u001b[0;34m(mp3_path, wav_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_mp3_to_wav\u001b[39m(mp3_path, wav_path):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert MP3 to WAV format for better compatibility\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     audio \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_mp3(mp3_path)\n\u001b[1;32m      9\u001b[0m     audio\u001b[38;5;241m.\u001b[39mexport(wav_path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wav_path\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydub/audio_segment.py:796\u001b[0m, in \u001b[0;36mAudioSegment.from_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_mp3\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_file(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m'\u001b[39m, parameters\u001b[38;5;241m=\u001b[39mparameters)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydub/audio_segment.py:728\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m     info \u001b[38;5;241m=\u001b[39m mediainfo_json(orig_file, read_ahead_limit\u001b[38;5;241m=\u001b[39mread_ahead_limit)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m    730\u001b[0m     audio_streams \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    731\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydub/utils.py:274\u001b[0m, in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[1;32m    271\u001b[0m         file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    273\u001b[0m command \u001b[38;5;241m=\u001b[39m [prober, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-of\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m command_args\n\u001b[0;32m--> 274\u001b[0m res \u001b[38;5;241m=\u001b[39m Popen(command, stdin\u001b[38;5;241m=\u001b[39mstdin_parameter, stdout\u001b[38;5;241m=\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39mPIPE)\n\u001b[1;32m    275\u001b[0m output, stderr \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mstdin_data)\n\u001b[1;32m    276\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1032\u001b[0m                         restore_signals,\n\u001b[1;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffprobe'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(mp3_path, wav_path):\n",
    "    \"\"\"Convert MP3 to WAV format for better compatibility\"\"\"\n",
    "    audio = AudioSegment.from_mp3(mp3_path)\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "    return wav_path\n",
    "\n",
    "def transcribe_with_diarization(audio_path):\n",
    "    \"\"\"Transcribe audio with speaker identification\"\"\"\n",
    "    # Load models\n",
    "    asr_model = whisper.load_model(\"medium\")\n",
    "    diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "    \n",
    "    # Perform diarization\n",
    "    diarization = diarization_pipeline(audio_path)\n",
    "    \n",
    "    # Perform transcription\n",
    "    transcription = asr_model.transcribe(audio_path, word_timestamps=True)\n",
    "    \n",
    "    # Align diarization with transcription\n",
    "    results = []\n",
    "    for segment in transcription[\"segments\"]:\n",
    "        speaker = \"Unknown\"\n",
    "        for turn, _, speaker_id in diarization.itertracks(yield_label=True):\n",
    "            if segment[\"start\"] >= turn.start and segment[\"end\"] <= turn.end:\n",
    "                speaker = speaker_id\n",
    "                break\n",
    "        \n",
    "        results.append({\n",
    "            \"start\": round(segment[\"start\"], 2),\n",
    "            \"end\": round(segment[\"end\"], 2),\n",
    "            \"speaker\": speaker,\n",
    "            \"text\": segment[\"text\"],\n",
    "            \"confidence\": round(segment.get(\"confidence\", 0), 2)\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"audio_file\": audio_path,\n",
    "        \"duration\": round(transcription[\"duration\"], 2),\n",
    "        \"language\": transcription[\"language\"],\n",
    "        \"speaker_count\": len(set([turn[2] for turn in diarization.itertracks(yield_label=True)])),\n",
    "        \"segments\": results,\n",
    "        \"metadata\": {\n",
    "            \"processing_time\": round(transcription[\"processing_time\"], 2),\n",
    "            \"model\": \"whisper-medium\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    input_mp3 = \"speech-94649.mp3\"\n",
    "    output_wav = \"speech.wav\"\n",
    "    output_json = \"speech.json\"\n",
    "    \n",
    "    # Convert MP3 to WAV\n",
    "    print(f\"Converting {input_mp3} to WAV format...\")\n",
    "    wav_path = convert_mp3_to_wav(input_mp3, output_wav)\n",
    "    \n",
    "    # Process the audio\n",
    "    print(\"Processing audio with transcription and diarization...\")\n",
    "    result = transcribe_with_diarization(wav_path)\n",
    "    \n",
    "    # Save results\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    \n",
    "    print(f\"Processing complete. Results saved to {output_json}\")\n",
    "    print(f\"Found {result['speaker_count']} speakers in {result['duration']} seconds of audio.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921b05f6-7ca2-4aff-89de-6309e0957a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydub, future, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-1.0.0 pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f5ff7d7-7acb-4f41-b8e3-694c47b4102d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2552295309.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    brew install ffmpeg\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cef8ee51-9718-4b7d-bd6b-e640c96aec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Collecting whisper\n",
      "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyannote.audio in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from whisper) (1.16.0)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.30.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (13.3.5)\n",
      "Requirement already satisfied: semver>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.audio) (1.7.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.66.4)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/lib/python3.12/site-packages (from lightning>=2.0.1->pyannote.audio) (2.5.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.12/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.9.2)\n",
      "Requirement already satisfied: optuna>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.3.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->pyannote.audio) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.4)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.9.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (2.2.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/anaconda3/lib/python3.12/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2024.8.30)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/anaconda3/lib/python3.12/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
      "Building wheels for collected packages: whisper\n",
      "  Building wheel for whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=1ee8e1459fd89999a0afedf9915ba8493142e197dd3af73b7e8e33b6b86a424f\n",
      "  Stored in directory: /Users/shubhamthakur/Library/Caches/pip/wheels/34/b8/4e/9c4c3351d670e06746a340fb4b7d854c76517eec225e5b32b1\n",
      "Successfully built whisper\n",
      "Installing collected packages: whisper\n",
      "Successfully installed whisper-1.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install torch whisper pyannote.audio pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536f4ea-d7f3-4f28-8e64-08d7d2ee1332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
